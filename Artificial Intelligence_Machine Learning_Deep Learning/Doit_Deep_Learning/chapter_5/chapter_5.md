# 검증 세트 나누고 전처리 과정 배우기  
  
## 하이퍼 파라미터(Hyperparameter)
* 매개변수의 값은 가중치나 절편처럼 알아서 학습되는 것이 아니라 사용자가 직접 선택하는 것이다. 이러한 사용자가 직접 설정하는 값을 하이퍼 파라미터 라고 한다.

## SVM(Support Vertor Machine:선형 서포트 벡터 머신)
* 훈련데이터의 클래스를 구분하는 경계선을 찾는 작업

## 모델 튜닝
* 성능에 만족을 걷기 위해서 매개변수의 값을 바꾸는 것

## 테스트 세트
* 실전에 투입된 모델의 성능을 측정하기 위해 서용
* 테스트 세트로 모델을 튜닝하면, 테스트 세트에 대해서만 좋은 성능을 내는 모델이 만들어 질 수 있다
* 이를 '테스트 세트의 정보가 모델에 새어 나갔다' 고 한다. 즉, 모델의 일반화 성능(generalization performance)이 왜곡된다.
* 테스트 세트는 모델 튜닝을 모두 마치고 마지막에 한번만 하는것이 좋다

## 검증 세트(Validation set)
* 모델을 튜닝하는 중에 성능을 확인하기 위해 필요한 데이터는 검증 세트이다.

## 데이터가 너무 적은 경우
* 데이터가 너무 적다면 검증 세트를 나누지 않고 교차 검증(cross validation)이라는 방법을 사용한다.
* 일반적으로 10만개의 자료가 있다면 8:1:1로 나누며 100 만개 이상의 데이터는 98:1:1로 나눈다.
* 검증과 테스트 세트의 샘플 수를 1만 개 이상 확보할 수 있다면 훈련 데이터에 많은 샘플을 할당 하는 것이 좋다.

## 데이터 전처리(data preprocessing)
* 잘 정리된 데이터도 전처리가 필요한 경우가 있는데 이는 데이터 특성의 스케일이 다른 경우이다

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994054-4074c280-a990-11ea-8dcf-3d02a5635506.png" width="50%"></p>

## 데이터 특성의 스케일(data scale)
* 어떤 특성이 가지고 있는 값의 범위
* 경사 하강법은 스케일에 민감한 알고리즘으로 특성의 스케일을 맞추는 전처리가 필요하다.

## 가중치를 기록할 변수와 하이퍼 파리미터 추가 & 가중치 기록하고 업데이트 양 조절
* learning rate는 하이퍼 파리미터 이며, 학습률을 의미한다.
* 가중치의 업데이트 양을 조절하는 역확을 하며, 일반적으로 손실 함수는 복잡한 굴곡을 가진 다차원 공간의 초평면(hyperplane)이다.
* 만약 가중치를 큰 폭으로 업데이트하여 손실 함수가 최소가 될 수 있는 지점인 전역 최솟값을 지나쳐 버리게 되면, 최적의 해(최적의 가중치와 절편)를 구할 수가 없다.
* 따라서 전역 최솟값을 놓치치 않도록 가중치의 업데이트 양을 조절할 필요가 있다.

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994114-67cb8f80-a990-11ea-962a-c21fec39fd50.png" width="50%"></p>

* 가중치의 최적값에 도달하는 동안 w3값이 크게 요동치므로 모델이 불안정하게 수렴한다는 것을 알 수 있다.
* 이는 스케일 조정으로 해결할 수 있다.

## 스케일 조정
### 표준화(standardization)
* z = x-m/s
* 특성값에서 평균을 빼고 표준편차로 나누면된다.
* 표준화를 하면 평균이 0이고, 분산이 1인 특성이 만들어진다.

### 표준편차
* 표준편차는 데이터가 얼마나 흩어져 있는지를 나타내는 지표로, 분산(variance)의 제곱근이다.

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994172-8c276c00-a990-11ea-8af4-f99662d85b08.png" width="20%"></p>

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994190-9d707880-a990-11ea-9683-373f043374e9.png" width="50%"></p>

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994203-a4978680-a990-11ea-9cd9-561bc5857a37.png" width="40%"><img src="https://user-images.githubusercontent.com/46274774/83994219-aa8d6780-a990-11ea-9895-1d4ab11b705b.png" width="40%"></p>

* 두 그래프를 보면 훈련 데이터와 검증 데이터가 다른 비율로 표준화된 것을 볼 수 있다.
* 원본 훈련 데이터와 원본 검증 데이터의 그래프에서의 거리는 변환후에도 같아야 한다.
* 따라서 같은 비율로 표준화를 해야한다.

# 과대 적합과 과소 적합
## 과대 적합 
* 모델이 훈련세트에서는 좋은 성능을 내지만 검증 세트에서는 낮은 성능을 내는 경우  
* 과대 적합된 모델을 분산이 크다(high variance)고 말한다
* 원인중 하나는 훈련 세트에 충분히 다양한 패턴의 샘플이 포함되지 않는 경우
* 더욱 많은 훈련 데이터를 모으면 이는 해결할 수 있는 문제이다.  
* 만약 데이터를 많이 모으기 힘들다면, 모델의 가중치를 제한 할 수 있다.(모델의 복잡도를 낮춘다)

## 과소 적합 
* 훈련 세트와 검증 세트의 성능 차이는 크지 않지만 모두 낮은 성능을 내는 경우
* 과소 적합된 모델을 편향이 크다(high bias)고 한다.
* 과소 적합은 충분히 모델이 복잡하지 않아서 훈련 데이터에 있는 패턴을 모두 잡지 못하는 경우이다.
* 복잡도가 더 높은 모델을 사용하거나, 가중치의 규제를 완화하면 이를 해결할 수 있다.

## 모델 복잡도
* 모델이 가지는 학습 가능한 가중치의 개수, 층이나 유닛의 개수가 많아지면 복잡도가 높은 모델이 만들어진다.

## 적절한 편향-분산 트레이드오프 선택
* 과소적합된 모델(편향)과 과대적합된 모델(분산) 사이의 관계를 편향-분산 트레이드오프(bias-varience tradeoff)라고 한다.
* 편향-분산 트레이드오프란 편향을 줄이면(훈련세트의 성능을 높이면) 분산이 커지고(검증 세트와 성능 차이가 커지고) 반대로 분산을 줄이면(검증 세트와 성능 차이를 줄이면) 편향이 커지는(훈련 세트의 성능이 낮아진다)것을 말한다.

# 규제 방법
* 가중치 규제란 가중치의 값이 커지지 않도록 제한하는 방법이다. 가중치를 규제하면 모델의 일반회된 성능이 높아진다.
* 모델이 몇개의 데이터에 집착하면 새로운 데이터에 적응을 못하므로 좋은 성능을 가졌다고 할 수 없다.(모델이 일반화되지 않았다)

## L1규제
* 손실 함수에 가중치의 절댓값인 L1노름(norm)을 추가한다.

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994408-50d96d00-a991-11ea-9494-636fc819c911.png" width="15%"></p>

* L1노름의 n은 가중치의 개수를 의미하므로, L1규제를 가중치의 절댓값을 손실 함수에 더한것으로 보아도 된다.

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994479-867e5600-a991-11ea-94df-2111fbd1d142.png" width="35%"></p>

* 손실 함수에 L1 노름을 더하면 L1규제가 만들어 진다. 이때 L1노름을 그냥 더하지 않고 &alpha;값을 곱해서 더하는데 &alpha;값은 규제의 양을 조절하는 하이퍼 파라미터이다.
* &alpha;값이 커지면 전체 손실 함수의 값이 커지지 않도록 가중치의 합이 작아져야 한다 (규제가 강해졌다 --> 가중치가 작아졌으므로)
* &alpha;의 값이 작아지면 손실 함수의 값이 커지므로 규제가 약해졌다고 한다.

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994530-ab72c900-a991-11ea-88f1-ec3adbc4a90f.png" width="35%"></p>

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994588-d3fac300-a991-11ea-9249-471a908dcd15.png" width="35%"></p>

* 절편에 대해 규제를 하지 않는 이유는 절편은 모델에 영향을 미치는 방식이 가중치와 달라서 이다. 절편을 규제하면 모델을 어떤 방향으로 이동시킬 뿐 복잡도에는 영향을 주지 않는다.
* 회귀 모델에 L1규제를 적용 --> 라쏘(Lasso)
* 라쏘는 가중치를 줄이다 못해 0으로 만들 수도 있다. 가중치가 0인 특성은 모델에서 사용할 수 없다는 것과 같다. 즉 특성을 선택할 수 있다는 효과를 얻을 수 있다.
* L1규제는 하이퍼 파라미터인 alpha에 많이 의존한다. 즉 가중치의 크기에 따라 규제의 양이 변하지 않으므로 규제효과가 좋지 않다.

## L2규제
* 손실 함수에 L2노름의 제곱을 더하면 L2규제이다.

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994745-52effb80-a992-11ea-94c9-281e403217b7.png" width="15%"></p>

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994837-83d03080-a992-11ea-8341-b257de33292d.png" width="35%"></p>

* &alpha;는 규제의 양을 조절하기 위한 하이퍼 파라미터 이다.

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994874-a6624980-a992-11ea-90f2-77aff391c340.png" width="30%"></p>

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994926-d4478e00-a992-11ea-9833-065ec435e8c9.png" width="35%"></p>

* L2규제를 미분하면 간단히 가중치 벡터인 w만 남는다.
* L2규제는 그레디언트 계산에 가중치의 값 자체가 포함되므로 가중치의 부호만 사용하는 L1규제 보다 조금 더 효과적이다.
* L2규제는 가중치를 완전히 0으로 만들지 않는다. 가중치를 0으로 만들면 특성을 제외하는 효과는 있지만, 모델의 복잡도가 떨어진다.
* 회귀 모델에 L2규제를 적용하면 릿지(Ridge)가 된다.

# K-폴드 교차 검증

<p align="center"><img src="https://user-images.githubusercontent.com/46274774/83994982-00fba580-a993-11ea-87ac-909503e2d4aa.png" width="50%"></p>

* 샘플 개수가 많지 않을때 검증 세트를 훈련 세트에서 분립하는라 훈련 세트의 샘플 개수가 줄어들어 모델을 훈련시킬 데이터가 부족해지는 경우 교차 검증을 사용한다.
* 훈련 세트를 동일한 크기의 폴드가 K개가 되도록 나눈다
* 각 폴드를 검증을 하기 위해 사용하고 나머지 폴드들은 훈련을 하기 위해 사용된다. 이 과정을 k번 반복하여 모델을 만든다.
* 코드에서 폴드를 나누기전 훈련 데이터를 전처리 한다면 이는 검증 데이터를 누설하는것이다. 검증 데이터를 나누고 나서 훈련 데이터를 전처리하는 것을 주의 해야 한다.
