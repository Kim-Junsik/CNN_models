{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wYx1SINE6BCZ","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SJja2ohSolFb","colab_type":"code","colab":{}},"source":["layers_in_block = {\n","    'resnet-18' : [2, 2, 2, 2],\n","    'resnet-34' : [3, 4, 6, 3],\n","    'resnet-50' : [3, 4, 6, 3],\n","    'resnet-101' : [3, 4, 23, 3],\n","    'resnet-152' : [3, 8, 36, 3]\n","    }\n","\n","class ResNet_Dense(tf.keras.layers.Layer):\n","  def __init__(self, pooling='avg', classes=1):\n","    super(ResNet_Dense, self).__init__()\n","    self.classes = classes\n","    self.pooling = pooling\n","\n","    self.avg_pooling = tf.keras.layers.GlobalAveragePooling2D()\n","    self.max_pooling = tf.keras.layers.GlobalMaxPooling2D()\n","\n","    self.sigmoid_fc = tf.keras.layers.Dense(units=classes, activation=tf.keras.activations.sigmoid)\n","    self.softmax_fc = tf.keras.layers.Dense(units=classes, activation=tf.keras.activations.softmax)\n","\n","\n","  def call(self, inputs):\n","    if self.pooling == 'avg':\n","      x = self.avg_pooling(inputs)\n","    elif self.pooling == 'max':\n","      x = self.max_pooling(inputs)\n","\n","    if self.classes == 1:\n","      x = self.sigmoid_fc(x)\n","    else:\n","      x = self.softmax_fc(x)\n","      \n","    return x\n","\n","def make_dense_layer(pooling='avg', classes=1):\n","  res_dense = tf.keras.Sequential()\n","  res_dense.add(ResNet_Dense(pooling=pooling, classes=classes))\n","  return res_dense"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ITFOE2b-cfGE","colab_type":"text"},"source":["## dimension을 맞추기 위해 stride 2 설정(basic, bottle commit)"]},{"cell_type":"code","metadata":{"id":"NUbMIdcAQDvt","colab_type":"code","colab":{}},"source":["class Basic_building_block(tf.keras.layers.Layer):\n","  def __init__(self, filter_num=None, kernel_size=(3, 3), \\\n","               stride=1, padding='same'):\n","    super(Basic_building_block, self).__init__()\n","    \n","    #First layer of the block\n","    self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n","                                       kernel_size=kernel_size,\n","                                       strides=stride,\n","                                       padding=padding)\n","    self.bn1 = tf.keras.layers.BatchNormalization()\n","\n","    #Second layer of the block\n","    self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n","                                        kernel_size=kernel_size,\n","                                        strides=1,\n","                                        padding=padding)\n","    self.bn2 = tf.keras.layers.BatchNormalization()\n","\n","    if stride != 1:\n","      self.downsample = tf.keras.Sequential()\n","      self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n","                                                  kernel_size=(1, 1),\n","                                                  strides=stride))\n","      self.downsample.add(tf.keras.layers.BatchNormalization())\n","    else:\n","      self.downsample = lambda x: x\n","\n","  def call(self, inputs, training=None):\n","    x_shortcut = self.downsample(inputs)\n","\n","    x = self.conv1(inputs)\n","    x = self.bn1(x, training=training)\n","    x = tf.nn.relu(x)\n","    x = self.conv2(x)\n","    x = self.bn2(x, training=training)\n","    x = tf.nn.relu(tf.keras.layers.add([x_shortcut, x]))\n","    \n","    return x\n","\n","def make_basic_block_layer(filter_num, blocks, stride=1):\n","  res_block = tf.keras.Sequential()\n","  for i in range(blocks):\n","    if stride==2 and i == 0:\n","      res_block.add(Basic_building_block(filter_num, stride=stride))\n","    else:\n","      res_block.add(Basic_building_block(filter_num, stride=1))\n","  return res_block\n","\n","class BasicResNet(tf.keras.Model):\n","  def __init__(self, layer='resnet-34', classes=1):\n","    super(BasicResNet, self).__init__()\n","\n","    self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(7, 7), strides=2, padding='same', kernel_initializer='he_normal')\n","    self.bn1 = tf.keras.layers.BatchNormalization(axis=3)\n","    self.max_pooling = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2)\n","\n","    self.res_block1 = make_basic_block_layer(64, layers_in_block[layer][0], 1)\n","    self.res_block2 = make_basic_block_layer(128, layers_in_block[layer][1], 2)\n","    self.res_block3 = make_basic_block_layer(256, layers_in_block[layer][2], 2)\n","    self.res_block4 = make_basic_block_layer(512, layers_in_block[layer][3], 2)\n","\n","    self.fc_block1 = make_dense_layer('avg', classes)\n","    \n","  def call(self, inputs, training=None):\n","    x = self.conv1(inputs)\n","    x = self.bn1(x, training=training)\n","    x = tf.nn.relu(x)\n","    x = self.max_pooling(x)\n","\n","    x = self.res_block1(x)\n","    x = self.res_block2(x)\n","    x = self.res_block3(x)\n","    x = self.res_block4(x)\n","\n","    x = self.fc_block1(x)\n","    \n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rfTOX_G0U0iu","colab_type":"code","colab":{}},"source":["class SEBlock(tf.keras.layers.Layer):\n","    def __init__(self, input_channels, r=16):\n","        super(SEBlock, self).__init__()\n","        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n","        self.fc1 = tf.keras.layers.Dense(units=input_channels // r)\n","        self.fc2 = tf.keras.layers.Dense(units=input_channels)\n","\n","    def call(self, inputs, **kwargs):\n","        branch = self.pool(inputs)\n","        branch = self.fc1(branch)\n","        branch = tf.nn.relu(branch)\n","        branch = self.fc2(branch)\n","        branch = tf.nn.sigmoid(branch)\n","        branch = tf.expand_dims(input=branch, axis=1)\n","        branch = tf.expand_dims(input=branch, axis=1)\n","        output = tf.keras.layers.multiply(inputs=[inputs, branch])\n","        return output\n","\n","\n","class ChannelAttention(tf.keras.layers.Layer):\n","    def __init__(self, in_planes, ratio=16):\n","        super(ChannelAttention, self).__init__()\n","        self.avg= tf.keras.layers.GlobalAveragePooling2D()\n","        self.max= tf.keras.layers.GlobalMaxPooling2D()\n","        self.conv1 = tf.keras.layers.Conv2D(filters = in_planes//ratio, \n","                                   kernel_size=1,\n","                                   kernel_initializer='he_normal', \n","                                   strides=1,\n","                                   padding='same')\n","        \n","        self.conv2 = tf.keras.layers.Conv2D(filters = in_planes, \n","                                            kernel_size=1,\n","                                            kernel_initializer='he_normal', \n","                                            strides=1, \n","                                            padding='same')\n","                                   \n","    def call(self, inputs):\n","        avg = self.avg(inputs)\n","        max = self.max(inputs)\n","        avg = tf.keras.layers.Reshape((1, 1, avg.shape[1]))(avg)   # shape (None, 1, 1 feature)\n","        max = tf.keras.layers.Reshape((1, 1, max.shape[1]))(max)   # shape (None, 1, 1 feature)\n","        avg_out = self.conv2(self.conv1(avg))\n","        avg_out = tf.nn.relu(avg_out)\n","        max_out = self.conv2(self.conv1(max))\n","        max_out = tf.nn.relu(max_out)\n","        out = avg_out + max_out\n","        out = tf.nn.sigmoid(out)\n","\n","        return out\n","\n","class SpatialAttention(tf.keras.layers.Layer):\n","    def __init__(self, kernel_size=7):\n","        super(SpatialAttention, self).__init__()\n","        self.conv1 = tf.keras.layers.Conv2D(filters = 1,\n","                                            kernel_size = kernel_size,\n","                                            kernel_initializer='he_normal',\n","                                            strides = 1,\n","                                            padding='same')\n","    def call(self, inputs):\n","        avg_out = tf.reduce_mean(inputs, axis=3)\n","        max_out = tf.reduce_max(inputs, axis=3)\n","        out = tf.stack([avg_out, max_out], axis=3)\n","        out = self.conv1(out)\n","        out = tf.nn.relu(out)\n","\n","        return out\n","\n","class ConvBlockAttentionModule(tf.keras.layers.Layer):\n","    def __init__(self, out_channels, ratio = 16, kernel_size = 7):\n","        super(ConvBlockAttentionModule, self).__init__()\n","        self.ca = ChannelAttention(in_planes = out_channels,\n","                                  ratio = ratio)\n","        self.sa = SpatialAttention(kernel_size= kernel_size)\n","\n","    def call(self, inputs, **kwargs):\n","      out = self.ca(inputs) * inputs\n","      out = self.sa(out) * out\n","\n","      return out\n","      \n","\n","class Bottle_building_block(tf.keras.layers.Layer):\n","    def __init__(self, filter_num=None, stride=2, se_block=False, cbam_block=False):\n","      super(Bottle_building_block, self).__init__()\n","      #First layer of the block\n","      self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n","                                        kernel_size=(1, 1),\n","                                        strides=1,\n","                                        padding='valid')\n","      self.bn1 = tf.keras.layers.BatchNormalization()\n","\n","      #Second layer of the block\n","      self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n","                                          kernel_size=(3, 3),\n","                                          strides=stride,\n","                                          padding='same')\n","      self.bn2 = tf.keras.layers.BatchNormalization()\n","\n","      #Three layer of the block\n","      self.conv3 = tf.keras.layers.Conv2D(filters=filter_num*4,\n","                                          kernel_size=(1, 1),\n","                                          strides=1,\n","                                          padding='valid')\n","      self.bn3 = tf.keras.layers.BatchNormalization()\n","\n","      #Convolution Attention Block\n","      self.use_se = se_block\n","      self.se_block = SEBlock(input_channels=filter_num * 4)\n","\n","      self.use_cbam = cbam_block\n","      self.cbam_block = ConvBlockAttentionModule(out_channels= filter_num * 4)\n","\n","      self.downsample = tf.keras.Sequential()\n","      self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num*4,\n","                                                kernel_size=(1, 1),\n","                                                strides=stride,\n","                                                padding='valid'))\n","      self.downsample.add(tf.keras.layers.BatchNormalization())\n","    \n","    def call(self, inputs, training=None):\n","      x_shortcut = self.downsample(inputs)\n","\n","      x = self.conv1(inputs)\n","      x = self.bn1(x, training=training)\n","      x = tf.nn.relu(x)\n","      x = self.conv2(x)\n","      x = self.bn2(x, training=training)\n","      x = tf.nn.relu(x)\n","      x = self.conv3(x)\n","      x = self.bn3(x, training=training)\n","      if self.use_se == True:\n","        x = self.se_block(x)\n","      if self.use_cbam == True:\n","        x = self.cbam_block(x)\n","\n","      x = tf.nn.relu(tf.keras.layers.add([x_shortcut, x]))\n","  \n","      return x\n","\n","def make_bottle_block_layer(filter_num, blocks, stride=2, use_se=False, use_cbam=False):\n","  res_block = tf.keras.Sequential()\n","  for i in range(blocks):\n","    if i == 0:\n","      res_block.add(Bottle_building_block(filter_num, stride=stride, se_block=use_se, cbam_block=use_cbam))\n","    else:\n","      res_block.add(Bottle_building_block(filter_num, stride=1, se_block=use_se, cbam_block=use_cbam))\n","  return res_block\n","\n","class BottleResNet(tf.keras.Model):\n","  def __init__(self, layer='resnet-101', se_block=False, cbam_block=False, classes=1):\n","    super(BottleResNet, self).__init__()\n","\n","    self.zero_padd_1 = tf.keras.layers.ZeroPadding2D(padding=(3, 3))\n","    self.conv1 = tf.keras.layers.Conv2D(filters=64, \n","                                        kernel_size=(7, 7), \n","                                        strides=2)\n","    self.bn1 = tf.keras.layers.BatchNormalization()\n","    self.zero_padd_2 = tf.keras.layers.ZeroPadding2D(padding=(1, 1))\n","    self.max_pooling = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), \n","                                                    strides=2)\n","\n","    self.res_block1 = make_bottle_block_layer(64, layers_in_block[layer][0], 1, use_se=se_block, use_cbam=cbam_block)\n","    self.res_block2 = make_bottle_block_layer(128, layers_in_block[layer][1], 2, use_se=se_block, use_cbam=cbam_block)\n","    self.res_block3 = make_bottle_block_layer(256, layers_in_block[layer][2], 2, use_se=se_block, use_cbam=cbam_block)\n","    self.res_block4 = make_bottle_block_layer(512, layers_in_block[layer][3], 2, use_se=se_block, use_cbam=cbam_block)\n","\n","    self.fc_block1 = make_dense_layer('avg', classes)\n","    \n","  def call(self, inputs, training=None, cam = None, feature_map = None):\n","    zero_padd_1 = self.zero_padd_1(inputs)\n","    conv_1 = self.conv1(zero_padd_1)\n","    bn_1 = self.bn1(conv_1, training=training)\n","    relu_1 = tf.nn.relu(bn_1)\n","    zero_padd_2 = self.zero_padd_2(relu_1)\n","    max_pool_1 = self.max_pooling(zero_padd_2)\n","\n","    res_block_1 = self.res_block1(max_pool_1)\n","    res_block_2 = self.res_block2(res_block_1)\n","    res_block_3 = self.res_block3(res_block_2)\n","    res_block_4 = self.res_block4(res_block_3)\n","\n","    x = self.fc_block1(res_block_4)\n","    if cam == 'grad':\n","      return res_block_4, x\n","    \n","    if feature_map == 'fm':\n","      return conv_1, bn_1, relu_1, max_pool_1, res_block_1, res_block_2, res_block_3, res_block_4, x\n","\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vfsOXVZgqpLN","colab_type":"code","colab":{}},"source":["def resnet_18(classes):\n","  return BasicResNet(layer='resnet-18', classes=classes)\n","\n","def resnet_34(classes):\n","  return BasicResNet(layer='resnet-34', classes=classes)\n","\n","def resnet_50(classes):\n","  return BottleResNet(layer='resnet-50', classes=classes)\n","\n","def resnet_101(classes):\n","  return BottleResNet(layer='resnet-101', classes=classes)\n","\n","def resnet_152(classes):\n","  return BottleResNet(layer='resnet-152', classes=classes)\n","\n","def se_resnet_50(classes):\n","  return BottleResNet(layer='resnet-50', se_block=True, classes=classes)\n","\n","def se_resnet_101(classes):\n","  return BottleResNet(layer='resnet-101', se_block=True, classes=classes)\n","\n","def se_resnet_152(classes):\n","  return BottleResNet(layer='resnet-152', se_block=True, classes=classes)\n","\n","def cbam_resnet_50(classes):\n","  return BottleResNet(layer='resnet-50', cbam_block=True, classes=classes)\n","\n","def cbam_resnet_101(classes):\n","  return BottleResNet(layer='resnet-101', cbam_block=True, classes=classes)\n","\n","def cbam_resnet_152(classes):\n","  return BottleResNet(layer='resnet-152', cbam_block=True, classes=classes)"],"execution_count":0,"outputs":[]}]}