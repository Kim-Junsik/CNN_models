{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EFFICIENTNET_B0_7.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"R0RE26r_LVHF","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import math"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mK22vqnFjF1T","colab_type":"code","colab":{}},"source":["def swish(x):\n","    return x * tf.nn.sigmoid(x)\n","\n","\n","def round_filters(filters, multiplier):\n","    depth_divisor = 8\n","    min_depth = None\n","    min_depth = min_depth or depth_divisor\n","    filters = filters * multiplier\n","    new_filters = max(min_depth, int(filters + depth_divisor / 2) // depth_divisor * depth_divisor)\n","    if new_filters < 0.9 * filters:\n","        new_filters += depth_divisor\n","    return int(new_filters)\n","\n","\n","def round_repeats(repeats, multiplier):\n","    if not multiplier:\n","        return repeats\n","    return int(math.ceil(multiplier * repeats))\n","\n","\n","class SEBlock(tf.keras.layers.Layer):\n","    def __init__(self, input_channels, ratio=0.25):\n","        super(SEBlock, self).__init__()\n","        self.num_reduced_filters = max(1, int(input_channels * ratio))\n","        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n","        self.reduce_conv = tf.keras.layers.Conv2D(filters=self.num_reduced_filters,\n","                                                  kernel_size=(1, 1),\n","                                                  strides=1,\n","                                                  padding=\"same\")\n","        self.expand_conv = tf.keras.layers.Conv2D(filters=input_channels,\n","                                                  kernel_size=(1, 1),\n","                                                  strides=1,\n","                                                  padding=\"same\")\n","\n","    def call(self, inputs, **kwargs):\n","        branch = self.pool(inputs)\n","        branch = tf.expand_dims(input=branch, axis=1)\n","        branch = tf.expand_dims(input=branch, axis=1)\n","        branch = self.reduce_conv(branch)\n","        branch = swish(branch)\n","        branch = self.expand_conv(branch)\n","        branch = tf.nn.sigmoid(branch)\n","        output = inputs * branch\n","        return output\n","        \n","\n","class ChannelAttention(tf.keras.layers.Layer):\n","    def __init__(self, in_planes, ratio=16):\n","        super(ChannelAttention, self).__init__()\n","        self.avg= tf.keras.layers.GlobalAveragePooling2D()\n","        self.max= tf.keras.layers.GlobalMaxPooling2D()\n","        self.conv1 = tf.keras.layers.Conv2D(filters = in_planes//ratio, \n","                                   kernel_size=1,\n","                                   kernel_initializer='he_normal', \n","                                   strides=1,\n","                                   padding='same')\n","        \n","        self.conv2 = tf.keras.layers.Conv2D(filters = in_planes, \n","                                            kernel_size=1,\n","                                            kernel_initializer='he_normal', \n","                                            strides=1, \n","                                            padding='same')\n","                                   \n","    def call(self, inputs):\n","        avg = self.avg(inputs)\n","        max = self.max(inputs)\n","        avg = tf.keras.layers.Reshape((1, 1, avg.shape[1]))(avg)   # shape (None, 1, 1 feature)\n","        max = tf.keras.layers.Reshape((1, 1, max.shape[1]))(max)   # shape (None, 1, 1 feature)\n","        avg_out = self.conv2(self.conv1(avg))\n","        avg_out = tf.nn.relu(avg_out)\n","        max_out = self.conv2(self.conv1(max))\n","        max_out = tf.nn.relu(max_out)\n","        out = avg_out + max_out\n","        out = tf.nn.sigmoid(out)\n","\n","        return out\n","\n","class SpatialAttention(tf.keras.layers.Layer):\n","    def __init__(self, kernel_size=7):\n","        super(SpatialAttention, self).__init__()\n","        self.conv1 = tf.keras.layers.Conv2D(filters = 1,\n","                                            kernel_size = kernel_size,\n","                                            kernel_initializer='he_normal',\n","                                            strides = 1,\n","                                            padding='same')\n","    def call(self, inputs):\n","        avg_out = tf.reduce_mean(inputs, axis=3)\n","        max_out = tf.reduce_max(inputs, axis=3)\n","        out = tf.stack([avg_out, max_out], axis=3)\n","        out = self.conv1(out)\n","        out = tf.nn.relu(out)\n","\n","        return out\n","\n","class ConvBlockAttentionModule(tf.keras.layers.Layer):\n","    def __init__(self, out_channels, ratio = 16, kernel_size = 7):\n","        super(ConvBlockAttentionModule, self).__init__()\n","        self.ca = ChannelAttention(in_planes = out_channels,\n","                                  ratio = ratio)\n","        self.sa = SpatialAttention(kernel_size= kernel_size)\n","\n","    def call(self, inputs, **kwargs):\n","      out = self.ca(inputs) * inputs\n","      out = self.sa(out) * out\n","\n","      return out\n","\n","\n","class MBConv(tf.keras.layers.Layer):\n","    def __init__(self, in_channels, out_channels, expansion_factor, stride, k, drop_connect_rate, use_se=True, use_cbam=False):\n","        super(MBConv, self).__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.stride = stride\n","        self.drop_connect_rate = drop_connect_rate\n","        self.conv1 = tf.keras.layers.Conv2D(filters=in_channels * expansion_factor,\n","                                            kernel_size=(1, 1),\n","                                            strides=1,\n","                                            padding=\"same\")\n","        self.bn1 = tf.keras.layers.BatchNormalization()\n","        self.dwconv = tf.keras.layers.DepthwiseConv2D(kernel_size=(k, k),\n","                                                      strides=stride,\n","                                                      padding=\"same\")\n","        self.bn2 = tf.keras.layers.BatchNormalization()\n","\n","        #Convolution Attention Block\n","        self.use_se = use_se\n","        self.se = SEBlock(input_channels=in_channels * expansion_factor)\n","        self.use_cbam = use_cbam\n","        self.cbam = ConvBlockAttentionModule(out_channels=in_channels * expansion_factor)\n","\n","        self.conv2 = tf.keras.layers.Conv2D(filters=out_channels,\n","                                            kernel_size=(1, 1),\n","                                            strides=1,\n","                                            padding=\"same\")\n","        self.bn3 = tf.keras.layers.BatchNormalization()\n","        self.dropout = tf.keras.layers.Dropout(rate=drop_connect_rate)\n","\n","    def call(self, inputs, training=None, **kwargs):\n","        x = self.conv1(inputs)\n","        x = self.bn1(x, training=training)\n","        x = swish(x)\n","        x = self.dwconv(x)\n","        x = self.bn2(x, training=training)\n","        if self.use_se == True:\n","            x = self.se(x)\n","        if self.use_cbam == True:\n","            x = self.cbam(x)\n","\n","        x = swish(x)\n","        x = self.conv2(x)\n","        x = self.bn3(x, training=training)\n","        if self.stride == 1 and self.in_channels == self.out_channels:\n","            if self.drop_connect_rate:\n","                x = self.dropout(x, training=training)\n","            x = tf.keras.layers.add([x, inputs])\n","        return x\n","\n","\n","def build_mbconv_block(in_channels, out_channels, layers, stride, expansion_factor, k, drop_connect_rate, use_se=True, use_cbam=False):\n","    block = tf.keras.Sequential()\n","    for i in range(layers):\n","        if i == 0:\n","            block.add(MBConv(in_channels=in_channels,\n","                             out_channels=out_channels,\n","                             expansion_factor=expansion_factor,\n","                             stride=stride,\n","                             k=k,\n","                             drop_connect_rate=drop_connect_rate,\n","                             use_se=use_se,\n","                             use_cbam=use_cbam))\n","        else:\n","            block.add(MBConv(in_channels=out_channels,\n","                             out_channels=out_channels,\n","                             expansion_factor=expansion_factor,\n","                             stride=1,\n","                             k=k,\n","                             drop_connect_rate=drop_connect_rate,\n","                             use_se=use_se,\n","                             use_cbam=use_cbam))\n","    return block\n","\n","\n","class EfficientNet(tf.keras.Model):\n","    def __init__(self, width_coefficient, depth_coefficient, dropout_rate=True, drop_connect_rate=0.2, use_se=False, use_cbam=False, classes=1):\n","        super(EfficientNet, self).__init__()\n","        self.classes = classes\n","\n","        self.conv1 = tf.keras.layers.Conv2D(filters=round_filters(32, width_coefficient),\n","                                            kernel_size=(3, 3),\n","                                            strides=2,\n","                                            padding=\"same\")\n","        self.bn1 = tf.keras.layers.BatchNormalization()\n","        self.block1 = build_mbconv_block(in_channels=round_filters(32, width_coefficient),\n","                                         out_channels=round_filters(16, width_coefficient),\n","                                         layers=round_repeats(1, depth_coefficient),\n","                                         stride=1,\n","                                         expansion_factor=1, k=3, drop_connect_rate=drop_connect_rate,\n","                                         use_se=use_se, use_cbam=use_cbam)\n","        self.block2 = build_mbconv_block(in_channels=round_filters(16, width_coefficient),\n","                                         out_channels=round_filters(24, width_coefficient),\n","                                         layers=round_repeats(2, depth_coefficient),\n","                                         stride=2,\n","                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate,\n","                                         use_se=use_se, use_cbam=use_cbam)\n","        self.block3 = build_mbconv_block(in_channels=round_filters(24, width_coefficient),\n","                                         out_channels=round_filters(40, width_coefficient),\n","                                         layers=round_repeats(2, depth_coefficient),\n","                                         stride=2,\n","                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate,\n","                                         use_se=use_se, use_cbam=use_cbam)\n","        self.block4 = build_mbconv_block(in_channels=round_filters(40, width_coefficient),\n","                                         out_channels=round_filters(80, width_coefficient),\n","                                         layers=round_repeats(3, depth_coefficient),\n","                                         stride=2,\n","                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate,\n","                                         use_se=use_se, use_cbam=use_cbam)\n","        self.block5 = build_mbconv_block(in_channels=round_filters(80, width_coefficient),\n","                                         out_channels=round_filters(112, width_coefficient),\n","                                         layers=round_repeats(3, depth_coefficient),\n","                                         stride=1,\n","                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate,\n","                                         use_se=use_se, use_cbam=use_cbam)\n","        self.block6 = build_mbconv_block(in_channels=round_filters(112, width_coefficient),\n","                                         out_channels=round_filters(192, width_coefficient),\n","                                         layers=round_repeats(4, depth_coefficient),\n","                                         stride=2,\n","                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate,\n","                                         use_se=use_se, use_cbam=use_cbam)\n","        self.block7 = build_mbconv_block(in_channels=round_filters(192, width_coefficient),\n","                                         out_channels=round_filters(320, width_coefficient),\n","                                         layers=round_repeats(1, depth_coefficient),\n","                                         stride=1,\n","                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate,\n","                                         use_se=use_se, use_cbam=use_cbam)\n","\n","        self.conv2 = tf.keras.layers.Conv2D(filters=round_filters(1280, width_coefficient),\n","                                            kernel_size=(1, 1),\n","                                            strides=1,\n","                                            padding=\"same\")\n","        self.bn2 = tf.keras.layers.BatchNormalization()\n","        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n","        self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n","        if classes != 1:\n","          self.fc1 = tf.keras.layers.Dense(units=classes,\n","                                        activation=tf.keras.activations.softmax)\n","        else:\n","          self.fc2 = tf.keras.layers.Dense(units=classes,\n","                                        activation=tf.keras.activations.sigmoid)\n","\n","    def call(self, inputs, training=None, cam=None, feature_map=None):\n","        conv_1 = self.conv1(inputs)\n","        bn_1 = self.bn1(conv_1, training=training)\n","        swish_1 = swish(bn_1)\n","\n","        block_1 = self.block1(swish_1)\n","        block_2 = self.block2(block_1)\n","        block_3 = self.block3(block_2)\n","        block_4 = self.block4(block_3)\n","        block_5 = self.block5(block_4)\n","        block_6 = self.block6(block_5)\n","        block_7 = self.block7(block_6)\n","\n","        conv_2 = self.conv2(block_7)\n","\n","        bn_2 = self.bn2(conv_2, training=training)\n","        swish_2 = swish(bn_2)\n","        global_avgpool = self.pool(swish_2)\n","        dropout = self.dropout(global_avgpool, training=training)\n","\n","        if self.classes != 1: \n","          x = self.fc1(dropout)\n","        else:\n","          x = self.fc2(dropout)\n","\n","        if cam == 'grad':\n","          return conv_2, x\n","\n","        if feature_map == 'fm':\n","          return conv_1, bn_1, swish_1, block_1, block_2, block_3, block_4, block_5, block_6, block_7, conv_2, bn_2, swish_2, global_avgpool, dropout, x\n","\n","        return x\n","\n","\n","def get_efficient_net(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, use_se=False, use_cbam=False, classes=1000):\n","    net = EfficientNet(width_coefficient=width_coefficient,\n","                       depth_coefficient=depth_coefficient,\n","                       dropout_rate=dropout_rate, \n","                       drop_connect_rate=dropout_rate, \n","                       use_se=use_se, \n","                       use_cbam=use_cbam, \n","                       classes=classes)\n","\n","    return net"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QU18GldcLcUu","colab_type":"code","colab":{}},"source":["def efficientnet_b0(classes):\n","    return get_efficient_net(1.0, 1.0, 224, 0.2, classes=classes)    \n","\n","def efficient_net_b1(classes):\n","    return get_efficient_net(1.0, 1.1, 240, 0.2, classes=classes)\n","\n","def efficient_net_b2(classes):\n","    return get_efficient_net(1.1, 1.2, 260, 0.3, classes=classes)\n","\n","def efficient_net_b3(classes):\n","    return get_efficient_net(1.2, 1.4, 300, 0.3, classes=classes)\n","\n","def efficient_net_b4(classes):\n","    return get_efficient_net(1.4, 1.8, 380, 0.4, classes=classes)\n","\n","def efficient_net_b5(classes):\n","    return get_efficient_net(1.6, 2.2, 456, 0.4, classes=classes)\n","\n","def efficient_net_b6(classes):\n","    return get_efficient_net(1.8, 2.6, 528, 0.5, classes=classes)\n","\n","def efficient_net_b7(classes):\n","    return get_efficient_net(2.0, 3.1, 600, 0.5, classes=classes)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F-UNmEiIXItk","colab_type":"code","colab":{}},"source":["def se_efficient_net_b0(classes):\n","    return get_efficient_net(1.0, 1.0, 224, 0.2, use_se=True, use_cbam=False, classes=classes)\n","\n","\n","def se_efficient_net_b1(classes):\n","    return get_efficient_net(1.0, 1.1, 240, 0.2, use_se=True, use_cbam=False, classes=classes)\n","\n","\n","def se_efficient_net_b2(classes):\n","    return get_efficient_net(1.1, 1.2, 260, 0.3, use_se=True, use_cbam=False, classes=classes)\n","\n","\n","def se_efficient_net_b3(classes):\n","    return get_efficient_net(1.2, 1.4, 300, 0.3, use_se=True, use_cbam=False, classes=classes)\n","\n","\n","def se_efficient_net_b4(classes):\n","    return get_efficient_net(1.4, 1.8, 380, 0.4, use_se=True, use_cbam=False, classes=classes)\n","\n","\n","def se_efficient_net_b5(classes):\n","    return get_efficient_net(1.6, 2.2, 456, 0.4, use_se=True, use_cbam=False, classes=classes)\n","\n","\n","def se_efficient_net_b6(classes):\n","    return get_efficient_net(1.8, 2.6, 528, 0.5, use_se=True, use_cbam=False, classes=classes)\n","\n","\n","def se_efficient_net_b7(classes):\n","    return get_efficient_net(2.0, 3.1, 600, 0.5, use_se=True, use_cbam=False, classes=classes)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"svvwQdqSkj6c","colab_type":"code","colab":{}},"source":["def cbam_efficient_net_b0(classes):\n","    return get_efficient_net(1.0, 1.0, 224, 0.2, use_se=False, use_cbam=True, classes=classes)\n","\n","\n","def cbam_efficient_net_b1(classes):\n","    return get_efficient_net(1.0, 1.1, 240, 0.2, use_se=False, use_cbam=True, classes=classes)\n","\n","\n","def cbam_efficient_net_b2(classes):\n","    return get_efficient_net(1.1, 1.2, 260, 0.3, use_se=False, use_cbam=True, classes=classes)\n","\n","\n","def cbam_efficient_net_b3(classes):\n","    return get_efficient_net(1.2, 1.4, 300, 0.3, use_se=False, use_cbam=True, classes=classes)\n","\n","\n","def cbam_efficient_net_b4(classes):\n","    return get_efficient_net(1.4, 1.8, 380, 0.4, use_se=False, use_cbam=True, classes=classes)\n","\n","\n","def cbam_efficient_net_b5(classes):\n","    return get_efficient_net(1.6, 2.2, 456, 0.4, use_se=False, use_cbam=True, classes=classes)\n","\n","\n","def cbam_efficient_net_b6(classes):\n","    return get_efficient_net(1.8, 2.6, 528, 0.5, use_se=False, use_cbam=True, classes=classes)\n","\n","\n","def cbam_efficient_net_b7(classes):\n","    return get_efficient_net(2.0, 3.1, 600, 0.5, use_se=False, use_cbam=True, classes=classes)\n"],"execution_count":0,"outputs":[]}]}