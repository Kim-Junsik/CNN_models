{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"efficientnet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"R0RE26r_LVHF","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import math\n","\n","def swish(x):\n","    return x * tf.nn.sigmoid(x)\n","\n","\n","def round_filters(filters, multiplier):\n","    depth_divisor = 8\n","    min_depth = None\n","    min_depth = min_depth or depth_divisor\n","    filters = filters * multiplier\n","    new_filters = max(min_depth, int(filters + depth_divisor / 2) // depth_divisor * depth_divisor)\n","    if new_filters < 0.9 * filters:\n","        new_filters += depth_divisor\n","    return int(new_filters)\n","\n","\n","def round_repeats(repeats, multiplier):\n","    if not multiplier:\n","        return repeats\n","    return int(math.ceil(multiplier * repeats))\n","\n","\n","class SEBlock(tf.keras.layers.Layer):\n","    def __init__(self, input_channels, ratio=0.25):\n","        super(SEBlock, self).__init__()\n","        self.num_reduced_filters = max(1, int(input_channels * ratio))\n","        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n","        self.reduce_conv = tf.keras.layers.Conv2D(filters=self.num_reduced_filters,\n","                                                  kernel_size=(1, 1),\n","                                                  strides=1,\n","                                                  padding=\"same\")\n","        self.expand_conv = tf.keras.layers.Conv2D(filters=input_channels,\n","                                                  kernel_size=(1, 1),\n","                                                  strides=1,\n","                                                  padding=\"same\")\n","\n","    def call(self, inputs, **kwargs):\n","        branch = self.pool(inputs)\n","        branch = tf.expand_dims(input=branch, axis=1)\n","        branch = tf.expand_dims(input=branch, axis=1)\n","        branch = self.reduce_conv(branch)\n","        branch = swish(branch)\n","        branch = self.expand_conv(branch)\n","        branch = tf.nn.sigmoid(branch)\n","        output = inputs * branch\n","        return output\n","\n","\n","class MBConv(tf.keras.layers.Layer):\n","    def __init__(self, in_channels, out_channels, expansion_factor, stride, k, drop_connect_rate):\n","        super(MBConv, self).__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.stride = stride\n","        self.drop_connect_rate = drop_connect_rate\n","        self.conv1 = tf.keras.layers.Conv2D(filters=in_channels * expansion_factor,\n","                                            kernel_size=(1, 1),\n","                                            strides=1,\n","                                            padding=\"same\")\n","        self.bn1 = tf.keras.layers.BatchNormalization()\n","        self.dwconv = tf.keras.layers.DepthwiseConv2D(kernel_size=(k, k),\n","                                                      strides=stride,\n","                                                      padding=\"same\")\n","        self.bn2 = tf.keras.layers.BatchNormalization()\n","        self.se = SEBlock(input_channels=in_channels * expansion_factor)\n","        self.conv2 = tf.keras.layers.Conv2D(filters=out_channels,\n","                                            kernel_size=(1, 1),\n","                                            strides=1,\n","                                            padding=\"same\")\n","        self.bn3 = tf.keras.layers.BatchNormalization()\n","        self.dropout = tf.keras.layers.Dropout(rate=drop_connect_rate)\n","\n","    def call(self, inputs, training=None, **kwargs):\n","        x = self.conv1(inputs)\n","        x = self.bn1(x, training=training)\n","        x = swish(x)\n","        x = self.dwconv(x)\n","        x = self.bn2(x, training=training)\n","        x = self.se(x)\n","        x = swish(x)\n","        x = self.conv2(x)\n","        x = self.bn3(x, training=training)\n","        if self.stride == 1 and self.in_channels == self.out_channels:\n","            if self.drop_connect_rate:\n","                x = self.dropout(x, training=training)\n","            x = tf.keras.layers.add([x, inputs])\n","        return x\n","\n","\n","def build_mbconv_block(in_channels, out_channels, layers, stride, expansion_factor, k, drop_connect_rate):\n","    block = tf.keras.Sequential()\n","    for i in range(layers):\n","        if i == 0:\n","            block.add(MBConv(in_channels=in_channels,\n","                             out_channels=out_channels,\n","                             expansion_factor=expansion_factor,\n","                             stride=stride,\n","                             k=k,\n","                             drop_connect_rate=drop_connect_rate))\n","        else:\n","            block.add(MBConv(in_channels=out_channels,\n","                             out_channels=out_channels,\n","                             expansion_factor=expansion_factor,\n","                             stride=1,\n","                             k=k,\n","                             drop_connect_rate=drop_connect_rate))\n","    return block\n","\n","\n","class EfficientNet(tf.keras.Model):\n","    def __init__(self, width_coefficient, depth_coefficient, dropout_rate, drop_connect_rate=0.2, classes=1):\n","        super(EfficientNet, self).__init__()\n","        self.classes = classes\n","\n","        self.conv1 = tf.keras.layers.Conv2D(filters=round_filters(32, width_coefficient),\n","                                            kernel_size=(3, 3),\n","                                            strides=2,\n","                                            padding=\"same\")\n","        self.bn1 = tf.keras.layers.BatchNormalization()\n","        self.block1 = build_mbconv_block(in_channels=round_filters(32, width_coefficient),\n","                                         out_channels=round_filters(16, width_coefficient),\n","                                         layers=round_repeats(1, depth_coefficient),\n","                                         stride=1,\n","                                         expansion_factor=1, k=3, drop_connect_rate=drop_connect_rate)\n","        self.block2 = build_mbconv_block(in_channels=round_filters(16, width_coefficient),\n","                                         out_channels=round_filters(24, width_coefficient),\n","                                         layers=round_repeats(2, depth_coefficient),\n","                                         stride=2,\n","                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate)\n","        self.block3 = build_mbconv_block(in_channels=round_filters(24, width_coefficient),\n","                                         out_channels=round_filters(40, width_coefficient),\n","                                         layers=round_repeats(2, depth_coefficient),\n","                                         stride=2,\n","                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate)\n","        self.block4 = build_mbconv_block(in_channels=round_filters(40, width_coefficient),\n","                                         out_channels=round_filters(80, width_coefficient),\n","                                         layers=round_repeats(3, depth_coefficient),\n","                                         stride=2,\n","                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate)\n","        self.block5 = build_mbconv_block(in_channels=round_filters(80, width_coefficient),\n","                                         out_channels=round_filters(112, width_coefficient),\n","                                         layers=round_repeats(3, depth_coefficient),\n","                                         stride=1,\n","                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate)\n","        self.block6 = build_mbconv_block(in_channels=round_filters(112, width_coefficient),\n","                                         out_channels=round_filters(192, width_coefficient),\n","                                         layers=round_repeats(4, depth_coefficient),\n","                                         stride=2,\n","                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate)\n","        self.block7 = build_mbconv_block(in_channels=round_filters(192, width_coefficient),\n","                                         out_channels=round_filters(320, width_coefficient),\n","                                         layers=round_repeats(1, depth_coefficient),\n","                                         stride=1,\n","                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate)\n","\n","        self.conv2 = tf.keras.layers.Conv2D(filters=round_filters(1280, width_coefficient),\n","                                            kernel_size=(1, 1),\n","                                            strides=1,\n","                                            padding=\"same\")\n","        self.bn2 = tf.keras.layers.BatchNormalization()\n","        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n","        self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n","        if classes != 1:\n","          self.fc1 = tf.keras.layers.Dense(units=classes,\n","                                        activation=tf.keras.activations.softmax)\n","        else:\n","          self.fc2 = tf.keras.layers.Dense(units=classes,\n","                                        activation=tf.keras.activations.sigmoid)\n","\n","    def call(self, inputs, training=None, cam=None):\n","        x = self.conv1(inputs)\n","        x = self.bn1(x, training=training)\n","        x = swish(x)\n","\n","        x = self.block1(x)\n","        x = self.block2(x)\n","        x = self.block3(x)\n","        x = self.block4(x)\n","        x = self.block5(x)\n","        x = self.block6(x)\n","        x = self.block7(x)\n","\n","        x_cam = self.conv2(x)\n","        x = self.bn2(x_cam, training=training)\n","        x = swish(x)\n","        x = self.pool(x)\n","        x = self.dropout(x, training=training)\n","        if self.classes != 1: \n","          x = self.fc1(x)\n","        else:\n","          x = self.fc1(x)\n","\n","        if cam == 'grad':\n","          return x_cam, x\n","\n","        return x\n","\n","\n","def get_efficient_net(width_coefficient, depth_coefficient, resolution, dropout_rate, classes):\n","    net = EfficientNet(width_coefficient=width_coefficient,\n","                       depth_coefficient=depth_coefficient,\n","                       dropout_rate=dropout_rate,\n","                       classes=classes)\n","\n","    return net\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QU18GldcLcUu","colab_type":"code","colab":{}},"source":["def efficient_net_b0(classes):\n","    return get_efficient_net(1.0, 1.0, 224, 0.2, classes)\n","\n","\n","def efficient_net_b1(classes):\n","    return get_efficient_net(1.0, 1.1, 240, 0.2, classes)\n","\n","\n","def efficient_net_b2(classes):\n","    return get_efficient_net(1.1, 1.2, 260, 0.3, classes)\n","\n","\n","def efficient_net_b3(classes):\n","    return get_efficient_net(1.2, 1.4, 300, 0.3, classes)\n","\n","\n","def efficient_net_b4(classes):\n","    return get_efficient_net(1.4, 1.8, 380, 0.4, classes)\n","\n","\n","def efficient_net_b5(classes):\n","    return get_efficient_net(1.6, 2.2, 456, 0.4, classes)\n","\n","\n","def efficient_net_b6(classes):\n","    return get_efficient_net(1.8, 2.6, 528, 0.5, classes)\n","\n","\n","def efficient_net_b7(classes):\n","    return get_efficient_net(2.0, 3.1, 600, 0.5, classes)\n"],"execution_count":0,"outputs":[]}]}