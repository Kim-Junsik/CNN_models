{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VggNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPaoEqQSt66HlWRNOAPx0tb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wcm84LIDBDex","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yCN4IMnRooe0","colab_type":"code","colab":{}},"source":["layer_in_block = {'vgg11': [1, 1, 2, 2, 2],\n","                  'vgg13': [2, 2, 2, 2, 2],\n","                  'vgg16': [2, 2, 3, 3, 3],\n","                  'vgg19': [2, 2, 4, 4, 4]}\n","\n","class SEBlock(tf.keras.layers.Layer):\n","    def __init__(self, input_channels, r=16):\n","        super(SEBlock, self).__init__()\n","        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n","        self.fc1 = tf.keras.layers.Dense(units=input_channels // r)\n","        self.fc2 = tf.keras.layers.Dense(units=input_channels)\n","\n","    def call(self, inputs, **kwargs):\n","        branch = self.pool(inputs)\n","        branch = self.fc1(branch)\n","        branch = tf.nn.relu(branch)\n","        branch = self.fc2(branch)\n","        branch = tf.nn.sigmoid(branch)\n","        branch = tf.expand_dims(input=branch, axis=1)\n","        branch = tf.expand_dims(input=branch, axis=1)\n","        output = tf.keras.layers.multiply(inputs=[inputs, branch])\n","        return output\n","\n","\n","class ChannelAttention(tf.keras.layers.Layer):\n","    def __init__(self, in_planes, ratio=16):\n","        super(ChannelAttention, self).__init__()\n","        self.avg= tf.keras.layers.GlobalAveragePooling2D()\n","        self.max= tf.keras.layers.GlobalMaxPooling2D()\n","        self.conv1 = tf.keras.layers.Conv2D(filters = in_planes//ratio, \n","                                   kernel_size=1,\n","                                   kernel_initializer='he_normal', \n","                                   strides=1,\n","                                   padding='same')\n","        \n","        self.conv2 = tf.keras.layers.Conv2D(filters = in_planes, \n","                                            kernel_size=1,\n","                                            kernel_initializer='he_normal', \n","                                            strides=1, \n","                                            padding='same')\n","                                   \n","    def call(self, inputs):\n","        avg = self.avg(inputs)\n","        max = self.max(inputs)\n","        avg = tf.keras.layers.Reshape((1, 1, avg.shape[1]))(avg)   # shape (None, 1, 1 feature)\n","        max = tf.keras.layers.Reshape((1, 1, max.shape[1]))(max)   # shape (None, 1, 1 feature)\n","        avg_out = self.conv2(self.conv1(avg))\n","        avg_out = tf.nn.relu(avg_out)\n","        max_out = self.conv2(self.conv1(max))\n","        max_out = tf.nn.relu(max_out)\n","        out = avg_out + max_out\n","        out = tf.nn.sigmoid(out)\n","\n","        return out\n","\n","class SpatialAttention(tf.keras.layers.Layer):\n","    def __init__(self, kernel_size=7):\n","        super(SpatialAttention, self).__init__()\n","        self.conv1 = tf.keras.layers.Conv2D(filters = 1,\n","                                            kernel_size = kernel_size,\n","                                            kernel_initializer='he_normal',\n","                                            strides = 1,\n","                                            padding='same')\n","    def call(self, inputs):\n","        avg_out = tf.reduce_mean(inputs, axis=3)\n","        max_out = tf.reduce_max(inputs, axis=3)\n","        out = tf.stack([avg_out, max_out], axis=3)\n","        out = self.conv1(out)\n","        out = tf.nn.relu(out)\n","\n","        return out\n","\n","class ConvBlockAttentionModule(tf.keras.layers.Layer):\n","    def __init__(self, out_channels, ratio = 16, kernel_size = 7):\n","        super(ConvBlockAttentionModule, self).__init__()\n","        self.ca = ChannelAttention(in_planes = out_channels,\n","                                  ratio = ratio)\n","        self.sa = SpatialAttention(kernel_size= kernel_size)\n","\n","    def call(self, inputs, **kwargs):\n","      out = self.ca(inputs) * inputs\n","      out = self.sa(out) * out\n","\n","      return out\n","\n","class VggConv(tf.keras.layers.Layer):\n","  def __init__(self, filter_num=None, kernel_size=(3, 3), \\\n","               activation='relu', padding='same', kernel_initializer='he_normal'):\n","    super(VggConv, self).__init__()\n","    self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n","                                        kernel_size=kernel_size,\n","                                        activation=activation,\n","                                        padding=padding,\n","                                        kernel_initializer=kernel_initializer)   \n","    \n","  def call(self, inputs, training=None):\n","    x = self.conv1(inputs)\n","    return x\n","\n","class VggConvs(tf.keras.layers.Layer):\n","  def __init__(self, pool_size=(2, 2)):\n","    super(VggConvs, self).__init__()\n","    self.bn1 = tf.keras.layers.BatchNormalization()\n","    \n","    self.pool1 = tf.keras.layers.MaxPool2D(pool_size=pool_size)\n","  \n","  def call(self, inputs, training=None):\n","    x = self.bn1(inputs, training=training)\n","    x = self.pool1(x)\n","    return x\n","\n","class VggDense(tf.keras.layers.Layer):\n","  def __init__(self, filter_num=None, classes=1):\n","    super(VggDense, self).__init__()\n","    self.Flatten = tf.keras.layers.Flatten()\n","    self.Dense1 = tf.keras.layers.Dense(filter_num, activation='relu')\n","    self.bn1 = tf.keras.layers.BatchNormalization()\n","    if classes == 1:\n","      self.Dense2 = tf.keras.layers.Dense(classes, activation=tf.keras.activations.sigmoid)\n","    else:\n","      self.Dense2 = tf.keras.layers.Dense(classes, activation=tf.keras.activations.softmax)\n","\n","  def call(self, inputs):\n","    x = self.Flatten(inputs)\n","    x = self.Dense1(x)\n","    x = self.bn1(x)\n","    x = self.Dense2(x)\n","\n","    return x\n","\n","\n","def vgg_convs_layer(filter_num=None, blocks=None,  kernel_size=(3, 3), \\\n","                    activation='relu', padding='same', kernel_initializer='he_normal', \\\n","                    pool_size=(2, 2), use_se = False, use_cbam = False):\n","  vgg_block = tf.keras.Sequential()\n","  for i in range(blocks):\n","    vgg_block.add(VggConv(filter_num=filter_num,  kernel_size=kernel_size, activation=activation, padding=padding, kernel_initializer=kernel_initializer))\n","  vgg_block.add(VggConvs(pool_size=pool_size))\n","  if use_se == True:\n","    vgg_block.add(SEBlock(input_channels=filter_num))\n","  if use_cbam == True:\n","    vgg_block.add(ConvBlockAttentionModule(out_channels = filter_num))\n","  return vgg_block\n","\n","\n","class VggNet(tf.keras.Model):\n","  def __init__(self, layer='vgg16', use_se = False, use_cbam = False, classes=1):\n","    super(VggNet, self).__init__()\n"," \n","    self.conv1 = vgg_convs_layer(filter_num = 64, blocks = layer_in_block[layer][0], use_se = use_se, use_cbam=use_cbam)\n","    self.conv2 = vgg_convs_layer(filter_num = 128, blocks =  layer_in_block[layer][1], use_se = use_se, use_cbam=use_cbam)\n","    self.conv3 = vgg_convs_layer(filter_num = 256, blocks = layer_in_block[layer][2], use_se = use_se, use_cbam=use_cbam)\n","    self.conv4 = vgg_convs_layer(filter_num = 512, blocks = layer_in_block[layer][3], use_se = use_se, use_cbam=use_cbam)\n","    self.conv5 = vgg_convs_layer(filter_num = 512, blocks = layer_in_block[layer][4], use_se = use_se, use_cbam=use_cbam)\n","    self.dense = VggDense(filter_num = 256, classes = classes)\n","\n","  def call(self, inputs, cam=None, feature_map=None):\n","    sequential_1 = self.conv1(inputs)\n","    sequential_2 = self.conv2(sequential_1)\n","    sequential_3 = self.conv3(sequential_2)\n","    sequential_4 = self.conv4(sequential_3)\n","    sequential_5 = self.conv5(sequential_4)\n","    x = self.dense(sequential_5)\n","\n","    if cam == 'grad':\n","      return sequential_5, x\n","\n","    if feature_map == 'fm':\n","      return sequential_1, sequential_2, sequential_3, sequential_4, sequential_5, x\n","    \n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i3I9dVMGsUCS","colab_type":"code","colab":{}},"source":["def vgg_11(classes):\n","  return VggNet(layer='vgg11', classes=classes)\n","\n","def vgg_13(classes):\n","  return VggNet(layer='vgg13', classes=classes)\n","\n","def vgg_16(classes):\n","  return VggNet(layer='vgg16', classes=classes)\n","\n","def vgg_19(classes):\n","  return VggNet(layer='vgg19', classes=classes)\n","\n","def se_vgg_16(classes):\n","  return VggNet(layer='vgg16', use_se = True, classes=classes)\n","\n","def se_vgg_19(classes):\n","  return VggNet(layer='vgg19', use_se = True, classes=classes)\n","\n","def cbam_vgg_16(classes):\n","  return VggNet(layer='vgg16', use_cbam = True, classes=classes)\n","\n","def cbam_vgg_19(classes):\n","  return VggNet(layer='vgg19', use_cbam = True, classes=classes)\n"],"execution_count":0,"outputs":[]}]}