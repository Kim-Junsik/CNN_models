{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"binary_model_tuning.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOodjIegINB+h5nh0JHoUwO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"VZyT6I_pYtsq","colab_type":"code","colab":{}},"source":["!pip install -q tensorflow-gpu==2.0.0-rc1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZG27hfSY9Qr","colab_type":"code","colab":{}},"source":["!pip install tf-nightly-gpu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ja9D4eMpZqOK","colab_type":"code","colab":{}},"source":["!pip install import_ipynb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-22a0KoOZBMd","colab_type":"code","colab":{}},"source":["# mount to your google drive\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vXS4MYDwd_gT","colab_type":"code","colab":{}},"source":["#ipynb 모듈 불러오기 위한 설정(model import)\n","import sys\n","sys.path.append('/content/gdrive/My Drive')\n","sys.path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YyrPzNotZEAE","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Input, BatchNormalization, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.utils import Sequence\n","\n","from PIL import Image\n","import math\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns\n","import cv2\n","\n","import import_ipynb\n","from model_class_cp import EFFICIENTNET_B0_7, MobileNet_V1, VggNet, ResNet, DenseNet\n","\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"otGbSQXgzfUj","colab_type":"text"},"source":["## 설정(경로, 텐서, 배치, 스텝, 에폭 등.)"]},{"cell_type":"code","metadata":{"id":"_GzIgT-OwdFl","colab_type":"code","colab":{}},"source":["#이미지 경로 설정.\n","train_PATH = '/content/gdrive/My Drive/dataset/train'\n","val_PATH = '/content/gdrive/My Drive/dataset/val'\n","test_PATH = '/content/gdrive/My Drive/dataset/test'\n","\n","#이미지 하이퍼파라미터.\n","train_batch = 10\n","val_batch = 10\n","test_batch = 10\n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224\n","IMG_CHANNELS = 3\n","\n","#훈련 하이퍼파라미터.\n","train_step = 80\n","val_step = 20\n","epoch = 300\n","history = {}\n","\n","#classes 하이퍼파라미터\n","NUM_CLASSES = 1\n","\n","#데이터셋(Augment part).\n","aug_dic = dict(rotation=True,\n","               flip_left_right = False,\n","               flip_up_down = True,\n","               color = False,\n","               zoom = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B9It1ItZzyzx","colab_type":"text"},"source":["## 모델 선택(해당 모델 번호 입력) "]},{"cell_type":"code","metadata":{"id":"ZoWrXTkKtH9-","colab_type":"code","colab":{}},"source":["def get_models(model_select):\n","  if model_select == 1:\n","    return VggNet.vgg_11(NUM_CLASSES)\n","  elif model_select == 2:\n","    return VggNet.vgg_13(NUM_CLASSES)\n","  elif model_select == 3:\n","    return VggNet.vgg_16(NUM_CLASSES)\n","  elif model_select == 4:\n","    return VggNet.vgg_19(NUM_CLASSES)\n","  elif model_select == 5:\n","    return VggNet.se_vgg_16(NUM_CLASSES)\n","  elif model_select == 6:\n","    return VggNet.se_vgg_19(NUM_CLASSES)\n","  elif model_select == 7:\n","    return VggNet.cbam_vgg_16(NUM_CLASSES)\n","  elif model_select == 8:\n","    return VggNet.cbam_vgg_19(NUM_CLASSES)\n","  elif model_select == 9:\n","    return ResNet.resnet_18(NUM_CLASSES)\n","  elif model_select == 10:\n","    return ResNet.resnet_34(NUM_CLASSES)\n","  elif model_select == 11:\n","    return ResNet.resnet_50(NUM_CLASSES)\n","  elif model_select == 12:\n","    return ResNet.resnet_101(NUM_CLASSES)\n","  elif model_select == 13:\n","    return ResNet.resnet_152(NUM_CLASSES)\n","  elif model_select == 14:\n","    return ResNet.se_resnet_50(NUM_CLASSES)\n","  elif model_select == 15:\n","    return ResNet.se_resnet_101(NUM_CLASSES)\n","  elif model_select == 16:\n","    return ResNet.se_resnet_152(NUM_CLASSES)\n","  elif model_select == 17:\n","    return ResNet.cbam_resnet_50(NUM_CLASSES)\n","  elif model_select == 18:\n","    return ResNet.cbam_resnet_101(NUM_CLASSES)\n","  elif model_select == 19:\n","    return ResNet.cbam_resnet_152(NUM_CLASSES)\n","  elif model_select == 20:\n","    return DenseNet.DenseNet_121(NUM_CLASSES)\n","  elif model_select == 21:\n","    return DenseNet.DenseNet_169(NUM_CLASSES)\n","  elif model_select == 22:\n","    return DenseNet.DenseNet_201(NUM_CLASSES)\n","  elif model_select == 23:\n","    return DenseNet.DenseNet_265(NUM_CLASSES)\n","  elif model_select == 24:\n","    return DenseNet.se_DenseNet_121(NUM_CLASSES)\n","  elif model_select == 25:\n","    return DenseNet.se_DenseNet_169(NUM_CLASSES)\n","  elif model_select == 26:\n","    return DenseNet.se_DenseNet_201(NUM_CLASSES)\n","  elif model_select == 27:\n","    return DenseNet.se_DenseNet_265(NUM_CLASSES)\n","  elif model_select == 28:\n","    return DenseNet.cbam_DenseNet_121(NUM_CLASSES)\n","  elif model_select == 29:\n","    return DenseNet.cbam_DenseNet_169(NUM_CLASSES)\n","  elif model_select == 30:\n","    return DenseNet.cbam_DenseNet_201(NUM_CLASSES)\n","  elif model_select == 31:\n","    return DenseNet.cbam_DenseNet_265(NUM_CLASSES)\n","  elif model_select == 32:\n","    return EFFICIENTNET_B0_7.efficient_net_b0(NUM_CLASSES)\n","  elif model_select == 33:\n","    return EFFICIENTNET_B0_7.efficient_net_b1(NUM_CLASSES)\n","  elif model_select == 34:\n","    return EFFICIENTNET_B0_7.efficient_net_b2(NUM_CLASSES)\n","  elif model_select == 35:\n","    return EFFICIENTNET_B0_7.efficient_net_b3(NUM_CLASSES)\n","  elif model_select == 36:\n","    return EFFICIENTNET_B0_7.efficient_net_b4(NUM_CLASSES)\n","  elif model_select == 37:\n","    return EFFICIENTNET_B0_7.efficient_net_b5(NUM_CLASSES)\n","  elif model_select == 38:\n","    return EFFICIENTNET_B0_7.efficient_net_b6(NUM_CLASSES)\n","  elif model_select == 39:\n","    return EFFICIENTNET_B0_7.efficient_net_b7(NUM_CLASSES)\n","  elif model_select == 40:\n","    return EFFICIENTNET_B0_7.cbam_efficient_net_b0(NUM_CLASSES)\n","  elif model_select == 41:\n","    return EFFICIENTNET_B0_7.cbam_efficient_net_b1(NUM_CLASSES)\n","  elif model_select == 42:\n","    return EFFICIENTNET_B0_7.cbam_efficient_net_b2(NUM_CLASSES)\n","  elif model_select == 43:\n","    return EFFICIENTNET_B0_7.cbam_efficient_net_b3(NUM_CLASSES)\n","  elif model_select == 44:\n","    return EFFICIENTNET_B0_7.cbam_efficient_net_b4(NUM_CLASSES)\n","  elif model_select == 45:\n","    return EFFICIENTNET_B0_7.cbam_efficient_net_b5(NUM_CLASSES)\n","  elif model_select == 46:\n","    return EFFICIENTNET_B0_7.cbam_efficient_net_b6(NUM_CLASSES)\n","  elif model_select == 47:\n","    return EFFICIENTNET_B0_7.cbam_efficient_net_b7(NUM_CLASSES)\n","  elif model_select == 48:\n","    return MobileNet_V1.MobileNet_V1(NUM_CLASSES)\n","  elif model_select == 49:\n","    return MobileNet_V1.se_MobileNet_V1(NUM_CLASSES)\n","  elif model_select == 50:\n","    return MobileNet_V1.cbam_MobileNet_V1(NUM_CLASSES)\n","  else:\n","    raise ValueError(\"The model_index does not exist.\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TfFpW_dMwhdQ","colab_type":"code","outputId":"d3c12ffb-28bd-4a5c-8c0d-076997241a98","executionInfo":{"status":"ok","timestamp":1585222576098,"user_tz":-540,"elapsed":2306,"user":{"displayName":"정규준","photoUrl":"","userId":"06773425004265186105"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model_select = int(input('Please enter the model index you want to use.'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Please enter the model index you want to use.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zxsIeKjRvLwe","colab_type":"code","colab":{}},"source":["get_model = get_models(model_select)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6B3XE5o50RL0","colab_type":"text"},"source":["# Dataset Directory & Data loader Implementation  "]},{"cell_type":"code","metadata":{"id":"65s61O-xvm7t","colab_type":"code","colab":{}},"source":["# 데이터 확인 함수\n","def check_images(train_path, val_path, test_path):\n","  train_cat_path = os.path.join(train_path,\"cat\")\n","  train_dog_path = os.path.join(train_path,\"dog\")\n","  val_cat_path = os.path.join(val_path,\"cat\")\n","  val_dog_path = os.path.join(val_path,\"dog\")\n","  test_cat_path = os.path.join(test_path,\"cat\")\n","  test_dog_path = os.path.join(test_path,\"dog\")\n","\n","  num_cats_tr = len(os.listdir(train_cat_path))\n","  num_dogs_tr = len(os.listdir(train_dog_path))\n","  num_cats_val = len(os.listdir(val_cat_path))\n","  num_dogs_val = len(os.listdir(val_dog_path))\n","  num_cats_test = len(os.listdir(test_cat_path))\n","  num_dogs_test = len(os.listdir(test_dog_path))\n","  label = ['train', 'valid','test']\n","  cat = [num_cats_tr,num_cats_val,num_cats_test]\n","  dog = [num_dogs_tr,num_dogs_val,num_dogs_test]\n","\n","  plt.rcParams[\"font.size\"] = 12\n","\n","  plt.figure(figsize=(12,8))\n","\n","  x = np.arange(len(label))\n","\n","  plt.bar(x-0.15, cat, label='cat', width=0.3, color='#FF0000')\n","  plt.bar(x+0.15, dog, label='dog', width=0.3, color='#0000FF')\n","  plt.legend()\n","  plt.xticks(x, label)\n","  plt.ylabel('Number of data')\n","  plt.title('Compare DATASETS')\n","\n","  plt.show()\n","  return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJU6FaLgwIl_","colab_type":"code","colab":{}},"source":["# 데이터 로더 동작 확인\n","def data_info_print(data_gen, idx):\n","  batch = data_gen.__getitem__(idx)\n","  print(type(batch), type(batch[0]), type(batch[1]))\n","  # 변경\n","  print(len(batch[0]), len(batch[1]))\n","  plt.figure(figsize=(20,8))\n","  for i in range(len(batch[0])):\n","    plt.subplot(2,5,i+1)\n","    # 변경 \n","    plt.imshow(batch[0][i])\n","    \n","  print('label :', batch[1])\n","  print(type(batch[0][0]), type(batch[1][0]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtVDiKoIwKcp","colab_type":"code","colab":{}},"source":["#Augment\n","class Augment:\n","  # rotation\n","  def __init__(self, rotation, flip_left_right, flip_up_down, color, zoom):\n","    self.rotation = rotation\n","    self.flip_left_right = flip_left_right\n","    self.flip_up_down = flip_up_down\n","    self.color = color\n","    self.zoom = zoom\n","\n","  def augmentation(self, img, size):\n","    if self.rotation:\n","      img=tf.image.rot90(img, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n","    # flip_left_right\n","    if self.flip_left_right:\n","      img = tf.image.flip_left_right(image=img)\n","\n","    # flip_up_down\n","    if self.flip_up_down:\n","      img = tf.image.flip_up_down(image=img)\n","\n","    # color augmentation\n","    if self.color:\n","      img = tf.image.random_hue(image=img, max_delta = 0.4)\n","      img = tf.image.random_contrast(image=img,lower=0.7,upper=1.3)\n","      img = tf.image.random_saturation(image=img, lower=0.6, upper=1.6)\n","      img = tf.image.random_brightness(image=img, max_delta=0.05)\n","\n","    # zoom\n","    if self.zoom:\n","      scales = list(np.arange(0.8, 1.0, 0.01))\n","      boxes = np.zeros((len(scales), 4))\n","      for i, scale in enumerate(scales):\n","          x1 = y1 = 0.5 - (0.5 * scale)\n","          x2 = y2 = 0.5 + (0.5 * scale)\n","          boxes[i] = [x1, y1, x2, y2]\n","      img = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=(224, 224))\n","      choice = tf.random.uniform(shape=[], minval=0, maxval=19, dtype=tf.int64)\n","      return img[choice]\n","    return img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYQmo7TAwPRd","colab_type":"code","colab":{}},"source":["class Dataset_file_ver:\n","    def __init__(self, augment = None, path='./', target_size=(224,224)):\n","      self.dir_path = path\n","      self.target_size = target_size\n","      self.Image_list = []\n","      self.Image_label = []\n","      self.augment = augment\n","      for index in range(len(os.listdir(self.dir_path))):\n","          # 클래스 라벨 추가 (고양이 : 0. , 개 : 1.)\n","          self.label = 1.0\n","          if os.listdir(self.dir_path)[index].startswith('cat'):\n","              self.label = 0.0\n","          # 이미지 경로를 저장해 나중에 배치만큼만 이미지를 불러온다.\n","          self.Image_list.append(os.path.join(self.dir_path, os.listdir(self.dir_path)[index]))\n","          # 클래스 라벨은 이미지 경로 순서대로 넣어준다.\n","          self.Image_label.append(self.label)\n","      print('Found {} images'.format(len(self.Image_list)))\n","      \n","    def __len__(self):\n","      # 이미지 경로를 담은 리스트 전체를 리턴한다.\n","      return len(self.Image_list)\n","\n","    def __getitem__(self, idx):\n","      # 호출 마다 한장의 이미지와 각 클래스 라벨을 같이 넘겨준다.\n","      img = image.load_img(self.Image_list[idx], target_size=self.target_size)\n","      img = image.img_to_array(img)\n","      img = img/255.0\n","      # image_augmentation\n","      if self.augment:\n","        img = self.augment.augmentation(img, self.target_size)\n","      #image = image.resize(self.target_size)\n","      return img, self.Image_label[idx]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7eqxBY4wTCV","colab_type":"code","colab":{}},"source":["class Dataset_dir_ver:\n","    def __init__(self, augment = None, path='./', target_size=(224,224)):\n","      self.dir_path = []\n","      self.target_size = target_size\n","      self.Image_list = []\n","      self.Image_label = []\n","      self.augment = augment\n","\n","      for in_dir in os.listdir(path):\n","        self.dir_path.append(os.path.join(path,in_dir))\n","\n","      for i in range(len(self.dir_path)):\n","        for index in range(len(os.listdir(self.dir_path[i]))):\n","            # 클래스 라벨 추가 (고양이 : 0. , 개 : 1.)\n","            self.label = 1.0\n","            if os.listdir(self.dir_path[i])[index].startswith('cat'):\n","                self.label = 0.0\n","            # 이미지 경로를 저장해 나중에 배치만큼만 이미지를 불러온다.\n","            self.Image_list.append(os.path.join(self.dir_path[i], os.listdir(self.dir_path[i])[index]))\n","            # 클래스 라벨은 이미지 경로 순서대로 넣어준다.\n","            self.Image_label.append(self.label)\n","      print('Found {} images'.format(len(self.Image_list)))\n","\n","    def __len__(self):\n","      # 이미지 경로를 담은 리스트 전체를 리턴한다.\n","      return len(self.Image_list)\n","\n","    def __getitem__(self, idx):\n","      # 호출 마다 한장의 이미지와 각 클래스 라벨을 같이 넘겨준다.\n","      img = image.load_img(self.Image_list[idx], target_size=self.target_size)\n","      img = image.img_to_array(img)\n","      img = img/255.0\n","      # image_augmentation\n","      if self.augment:\n","        img = self.augment.augmentation(img, self.target_size)\n","      #image = image.resize(self.target_size)\n","      # 변경\n","      return img, self.Image_label[idx]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HyETaqckwU9U","colab_type":"code","colab":{}},"source":["class Data_Loader(Sequence):\n","\n","    def __init__(self, dataset, batch_size=None, shuffle=False):\n","      # 데이터셋을 맴버로 가지며 데이터셋을 호출해 배치만큼 사진을 가지고 온다.\n","      self.dataset = dataset\n","      self.batch_size = batch_size\n","      self.shuffle=shuffle\n","      self.index_list = [idx for idx in range(len(self.dataset))]\n","      self.idx=0\n","    def __getitem__(self, idx):\n","      # 시작과 끝 인덱스 지정 --> 배치 사이즈만큼 for 루프를 실행하며 사진을 넘파이 배열에 저장한다.\n","      start = idx * self.batch_size\n","      end = (idx+1) * self.batch_size\n","      data = []\n","      label = []\n","      if self.shuffle:\n","        np.random.shuffle(self.index_list)\n","      # 변경\n","      # 배치사이즈 만큼 사진과 라벨을 리스트에 저장한다.\n","      for j in range(start,end):\n","        if j >= len(self.index_list):\n","          j%=len(self.dataset)\n","        data.append(self.dataset[self.index_list[j]])\n","      # 사진은 사진끼리 라벨은 라벨끼리 묶어서 리턴한다.\n","      #batch = tuple(sample for sample in zip(*data))\n","      batch = tuple(tf.stack(sample, axis=0) for sample in zip(*data))\n","\n","      if self.idx >= (len(self.dataset)//self.batch_size):\n","        self.idx=0\n","      self.idx +=1\n","      return batch\n","\n","    def __call__(self):\n","      batch = self.__getitem__(self.idx)\n","      return batch\n","\n","    def __len__(self):\n","      # 데이터셋을 크기를 배치 사이즈로 나누어 준다.\n","        return (len(self.dataset) // self.batch_size)\n","\n","    def get_batch(self):\n","      return self.batch_size"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iFQghyCd0YyE","colab_type":"text"},"source":["# 데이터 확인 & 데이터 로더 생성\n","\n"]},{"cell_type":"code","metadata":{"id":"xC25AUEWwlWr","colab_type":"code","colab":{}},"source":["# 데이터 확인\n","check_images(train_path=train_PATH, val_path=val_PATH, test_path=test_PATH)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OLRqsJyJwtDM","colab_type":"code","colab":{}},"source":["train_augment = Augment(**aug_dic)\n","train_dataset = Dataset_dir_ver(augment = train_augment, path=train_PATH)\n","train_data_gen = Data_Loader(dataset=train_dataset, batch_size=train_batch, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YaSHSsMwwv9s","colab_type":"code","colab":{}},"source":["val_dataset = Dataset_dir_ver(path=val_PATH)\n","val_data_gen = Data_Loader(dataset=val_dataset, batch_size=test_batch, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IwY8_80ZwwhF","colab_type":"code","colab":{}},"source":["test_dataset = Dataset_dir_ver(path=test_PATH)\n","test_data_gen = Data_Loader(dataset=test_dataset, batch_size=test_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ydru_9xM0dZD","colab_type":"text"},"source":["# train, val, test 데이터 로더의 출력 값과 형태, 타입, 갯수(배치 사이즈) augmentation된 사진 확인"]},{"cell_type":"code","metadata":{"id":"vlXjaipdwy1W","colab_type":"code","colab":{}},"source":["data_info_print(train_data_gen,0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0pJKzScw2Kw","colab_type":"code","colab":{}},"source":["data_info_print(val_data_gen, 399)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fhxp2_nBw3sl","colab_type":"code","colab":{}},"source":["data_info_print(test_data_gen, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F_HSzCeK0g9p","colab_type":"text"},"source":["# 모델 훈련  \n","### Using GradientTape\n"]},{"cell_type":"code","metadata":{"id":"8CmrireBw5q1","colab_type":"code","colab":{}},"source":["def fit_test(model, train_gen, train_steps, epochs, val_gen, val_steps):\n","  BATCH_SIZE = train_gen.get_batch()\n","  # define loss and optimizer\n","  optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n","  loss_func = keras.losses.BinaryCrossentropy()\n","\n","  train_loss = tf.keras.metrics.Mean(name='train_loss')\n","  train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n","\n","  valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n","  valid_accuracy = tf.keras.metrics.BinaryAccuracy(name='valid_accuracy')\n","\n","\n","  train_losses = []\n","  train_acces = []\n","  val_losses = []\n","  val_acces = []\n","\n","\n","  @tf.function\n","  def train_step(images, labels):\n","      with tf.GradientTape() as tape:\n","          predictions = model(images, training=True)\n","          loss = loss_func(y_true=labels, y_pred=predictions)\n","      gradients = tape.gradient(loss, model.trainable_variables)\n","      optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))\n","\n","      train_loss(loss)\n","      train_accuracy(labels, predictions)\n","\n","  @tf.function\n","  def valid_step(images, labels):\n","\n","    predictions = model(images, training=False)\n","    v_loss = loss_func(labels, predictions)\n","\n","    valid_loss(v_loss)\n","    valid_accuracy(labels, predictions)\n","  \n","  def step_decay(epoch):\n","   drop = 0.5\n","   epochs_drop = 10.0\n","   optimizer.learning_rate = optimizer.learning_rate * math.pow(drop,  \n","           math.floor((1+epoch)/epochs_drop))\n","   print('step_decay is %6.4f.' % (optimizer.learning_rate))\n","\n","  LR_SCHEDULE = [\n","    # (epoch to start, learning rate) tuples\n","    (2, 0.0005), (3, 0.0001)\n","  ]\n","\n","  def lr_schedule(epoch, lr):\n","    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n","    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n","      return lr\n","    for i in range(len(LR_SCHEDULE)):\n","      if epoch == LR_SCHEDULE[i][0]:\n","        return LR_SCHEDULE[i][1]\n","    return lr\n","\n","  def LearningRateScheduler(epoch, lr):\n","    if not hasattr(optimizer, 'lr'):\n","      raise ValueError('Optimizer must have a \"lr\" attribute.')\n","    # Get the current learning rate from model's optimizer.\n","    lr = float(tf.keras.backend.get_value(optimizer.learning_rate))\n","    # Call schedule function to get the scheduled learning rate.\n","    scheduled_lr = lr_schedule(epoch, lr)\n","    # Set the value back to the optimizer before this epoch starts\n","    tf.keras.backend.set_value(optimizer.learning_rate, scheduled_lr)\n","    print('\\nEpoch %05d: Learning rate is %6.4f.' % (epoch, optimizer.learning_rate))\n","\n","  # start training\n","  for epoch in range(epochs):\n","    #LearningRateScheduler(epoch, optimizer.learning_rate)\n","    step_decay(epoch)\n","\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","    valid_loss.reset_states()\n","    valid_accuracy.reset_states()\n","    #step = 0\n","    for step in range(train_steps):\n","      print('.',end='')\n","      if step % 100 == 0:\n","        print()\n","      images, labels = train_data_gen()\n","      train_step(images, labels)\n","    print('x')\n","    for val_step in range(val_steps):\n","      print('.', end='')\n","      if val_step % 100 == 0:\n","        print()\n","      valid_images, valid_labels = val_data_gen()\n","      valid_step(valid_images, valid_labels)\n","    print('x')\n","    print(\"Epoch: {}/{}, train loss: {:.5f}, train accuracy: {:.5f}, \"\n","          \"valid loss: {:.5f}, valid accuracy: {:.5f}\".format(epoch + 1,\n","                                                              epochs,\n","                                                              train_loss.result(),\n","                                                              train_accuracy.result(),\n","                                                              valid_loss.result(),\n","                                                              valid_accuracy.result()))\n","    train_losses.append(train_loss.result())\n","    train_acces.append(train_accuracy.result())\n","    val_losses.append(valid_loss.result())\n","    val_acces.append(valid_accuracy.result())\n","\n","  history = {'train_losses': train_losses, 'train_acces': train_acces, 'val_losses': val_losses, 'val_acces': val_acces}\n","  return history"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAnBLmbkw6Pk","colab_type":"code","colab":{}},"source":[" def test_eval(model, test_data_gen, test_steps):\n","  loss_func = keras.losses.BinaryCrossentropy()\n","  test_loss = tf.keras.metrics.Mean()\n","  test_accuracy = tf.keras.metrics.BinaryAccuracy()\n","\n","  @tf.function\n","  def test_step(images, labels):\n","      predictions = model(images, training=False)\n","      t_loss = loss_func(labels, predictions)\n","\n","      test_loss(t_loss)\n","      test_accuracy(labels, predictions)\n","\n","  for step in range(test_steps):\n","    print('.',end='')\n","    if step % 100 == 0:\n","      print()\n","    test_images, test_labels = test_data_gen()\n","    test_step(test_images, test_labels)\n","  print('x')\n","  print(\"loss: {:.5f}, test accuracy: {:.5f}\".format(test_loss.result(),\n","                                                      test_accuracy.result()))\n","\n","  #print(\"The accuracy on test set is: {:.3f}%\".format(test_accuracy.result()*100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j23bzUsTw75C","colab_type":"code","colab":{}},"source":["get_model.build(input_shape=(None, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHBrGQMtxaPP","colab_type":"code","colab":{}},"source":["get_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ToyY5HaSxcxJ","colab_type":"code","colab":{}},"source":["history = fit_test(model=get_model, \n","                   train_gen=train_data_gen, \n","                   train_steps=train_step, \n","                   epochs=epoch, \n","                   val_gen=val_data_gen, \n","                   val_steps=val_step)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yn7L6jCNU86I","colab_type":"code","colab":{}},"source":["test_eval(get_model, test_data_gen, 400)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jzRy9pe10oqt","colab_type":"text"},"source":["# 저장"]},{"cell_type":"code","metadata":{"id":"i2A_deCzxosH","colab_type":"code","colab":{}},"source":["get_model.save_weights('/content/gdrive/My Drive/MobileNet_v1_850', save_format='tf')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wBgE6YcAAHn_","colab_type":"text"},"source":["## 로드"]},{"cell_type":"code","metadata":{"id":"qhOaBwIRAJMG","colab_type":"code","colab":{}},"source":["get_model.load_weights('/content/gdrive/My Drive/MobileNet_v1_500')   "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ioXEZwcf0q7Z","colab_type":"text"},"source":["# 모델 학습 가시화 그래프\n"]},{"cell_type":"code","metadata":{"id":"km0nmVryxvq7","colab_type":"code","colab":{}},"source":["def his_graph(history, epoch):\n","  acc = history['train_acces']\n","  val_acc = history['val_acces']\n","\n","  loss = history['train_losses']\n","  val_loss = history['val_losses']\n","\n","  epochs_range = range(epoch)\n","\n","  plt.figure(figsize=(8, 8))\n","  plt.subplot(2, 1, 1)\n","  plt.plot(epochs_range, acc, label='Training Accuracy')\n","  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","  plt.legend(loc='lower right')\n","  plt.title('Training and Validation Accuracy')\n","\n","  plt.subplot(2, 1, 2)\n","  plt.plot(epochs_range, loss, label='Training Loss')\n","  plt.plot(epochs_range, val_loss, label='Validation Loss')\n","  plt.legend(loc='upper right')\n","  plt.title('Training and Validation Loss')\n","\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_NAHJelxx1g","colab_type":"code","colab":{}},"source":["his_graph(history, epoch)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FeuQ9fP8ckyo","colab_type":"text"},"source":["#모델 예측 및 가시화(confusion matrix)"]},{"cell_type":"code","metadata":{"id":"ASJEoHFJxz5e","colab_type":"code","colab":{}},"source":["def model_predict(model, test_gen, steps):\n","  predics=[]\n","  labels = []\n","  for step in range(steps):\n","    image,label = test_gen()\n","    pred = model(image)\n","    labels.append(label)\n","    predics.append(pred)\n","  re_dic = dict({'pred':predics, 'labels':labels})\n","  return re_dic"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cscbzdLmx3HI","colab_type":"code","colab":{}},"source":["pred_dataset = Dataset_dir_ver(path=test_PATH)\n","pred_data_gen = Data_Loader(dataset=test_dataset, batch_size=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UZ02piGnx3r3","colab_type":"code","colab":{}},"source":["def pred_confusion_matrix(pred, labels):\n","  pred_int = []\n","  for i in range(len(pred)):\n","    if pred[i] > 0.5:\n","      pred_int.append(1)\n","    elif pred[i] <= 0.5:\n","      pred_int.append(0)\n","\n","  print(len(pred))\n","  print(len(pred_int))\n","  print('Confusion Matrix')\n","  conf_matrix = confusion_matrix(labels, pred_int)\n","  print(conf_matrix)\n","  sns.heatmap(conf_matrix,cmap=\"Blues\",annot=True,fmt='g');\n","  plt.xlabel('predicted value')\n","  plt.ylabel('true value');"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2o2Hj5jx72a","colab_type":"code","colab":{}},"source":["re_dic = model_predict(get_model, pred_data_gen, 4000)\n","pred = re_dic['pred']\n","labels = re_dic['labels']\n","pred = list(map(float,pred))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TB7AY_CCx8xA","colab_type":"code","colab":{}},"source":["pred_confusion_matrix(pred, labels)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kKoUWvCYcv-N","colab_type":"text"},"source":["#Grad CAM"]},{"cell_type":"code","metadata":{"id":"xZLLcjobbOmN","colab_type":"code","colab":{}},"source":["def grad_cam(model, idx, class_name):\n","  plt.figure(figsize=(18, 15))\n","  for i in range(40,50):\n","    path = os.path.join('/content/gdrive/My Drive/cvpr_data/images/Train_%d.jpg'%i)\n","    image = cv2.imread(path)\n","    img = cv2.resize(image, (IMAGE_SHAPE[0], IMAGE_SHAPE[1]))\n","    x = img.copy()\n","    x.astype(np.float32)\n","    x = np.expand_dims(x, axis=0)\n","    x = x / 255.0\n","    \n","    #grad_model = tf.keras.models.Model(\n","    #      [resnet101.layers[0]], [resnet101.layers[-2],resnet101.layers[-1]]\n","    #  )\n","      \n","    with tf.GradientTape() as tape:\n","        inputs = tf.cast(x, tf.float32)\n","        model_outputs, predictions = model(inputs, cam = 'grad')\n","        loss = predictions[:,0]\n","\n","    grads = tape.gradient(loss, model_outputs)\n","\n","    guided_grads = (\n","          tf.cast(model_outputs > 0, \"float32\") * tf.cast(grads > 0, \"float32\") * grads\n","    )\n","\n","    prediction = predictions[0][idx]\n","    model_outputs = model_outputs[0]\n","    plt.subplot(4, 5, i-40+1)\n","    weights = np.mean(grads, axis=(1, 2))\n","    weights = weights.reshape(2048, 1)\n","\n","    cam = (prediction -0.5) * np.matmul(model_outputs, weights)\n","    cam -= np.min(cam)\n","    cam /= np.max(cam)\n","    cam -= 0.2\n","    cam /= 0.8\n","\n","    try:\n","      cam = cv2.resize(np.float32(cam), (IMAGE_SHAPE[0], IMAGE_SHAPE[1]))\n","    except Exception as e:\n","      #print(cam.shape)\n","      print(str(e))\n","\n","    heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n","    heatmap[np.where(cam <= 0.2)] = 0\n","    grad_cam = cv2.addWeighted(img, 0.8, heatmap, 0.4, 0)\n","    plt.axis('off')\n","    plt.title('%s_class_grad_cam'%class_name)\n","    plt.imshow(grad_cam[:, :, ::-1])"],"execution_count":0,"outputs":[]}]}